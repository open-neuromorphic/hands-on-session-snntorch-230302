{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"10VOBz8G0dFupvaGmRhdL5kj3bfAiCz0Z","timestamp":1677775550843},{"file_id":"1JqZzSJZk7CXXJA5vBOEKnpGVQUpHCQ9o","timestamp":1677721881214}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"gpuClass":"standard"},"cells":[{"cell_type":"markdown","source":["# Open Neuromorphic Seminar - Hands-On with snnTorch\n","## By Jason K. Eshraghian (www.ncg.ucsc.edu)\n","\n","\n","[<img src='https://github.com/jeshraghian/snntorch/blob/master/docs/_static/img/snntorch_alpha_w.png?raw=true' width=\"200\">](https://github.com/jeshraghian/snntorch/)"],"metadata":{"id":"8w6lhn7H8fW5"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"1BlTqunB73-t"},"outputs":[],"source":["!pip install snntorch --quiet"]},{"cell_type":"code","source":["#@title Plotting Settings\n","def plot_cur_mem_spk(cur, mem, spk, thr_line=False, vline=False, title=False, ylim_max1=1.25, ylim_max2=1.25):\n","  # Generate Plots\n","  fig, ax = plt.subplots(3, figsize=(8,6), sharex=True, \n","                        gridspec_kw = {'height_ratios': [1, 1, 0.4]})\n","\n","  # Plot input current\n","  ax[0].plot(cur, c=\"tab:orange\")\n","  ax[0].set_ylim([0, ylim_max1])\n","  ax[0].set_xlim([0, 200])\n","  ax[0].set_ylabel(\"Input Current ($I_{in}$)\")\n","  if title:\n","    ax[0].set_title(title)\n","\n","  # Plot membrane potential\n","  ax[1].plot(mem)\n","  ax[1].set_ylim([0, ylim_max2]) \n","  ax[1].set_ylabel(\"Membrane Potential ($U_{mem}$)\")\n","  if thr_line:\n","    ax[1].axhline(y=thr_line, alpha=0.25, linestyle=\"dashed\", c=\"black\", linewidth=2)\n","  plt.xlabel(\"Time step\")\n","\n","  # Plot output spike using spikeplot\n","  splt.raster(spk, ax[2], s=400, c=\"black\", marker=\"|\")\n","  if vline:\n","    ax[2].axvline(x=vline, ymin=0, ymax=6.75, alpha = 0.15, linestyle=\"dashed\", c=\"black\", linewidth=2, zorder=0, clip_on=False)\n","  plt.ylabel(\"Output spikes\")\n","  plt.yticks([]) \n","\n","  plt.show()\n","\n","def plot_snn_spikes(spk_in, spk1_rec, spk2_rec, title):\n","  # Generate Plots\n","  fig, ax = plt.subplots(3, figsize=(8,7), sharex=True, \n","                        gridspec_kw = {'height_ratios': [1, 1, 0.4]})\n","\n","  # Plot input spikes\n","  splt.raster(spk_in[:,0], ax[0], s=0.03, c=\"black\")\n","  ax[0].set_ylabel(\"Input Spikes\")\n","  ax[0].set_title(title)\n","\n","  # Plot hidden layer spikes\n","  splt.raster(spk1_rec.reshape(num_steps, -1), ax[1], s = 0.05, c=\"black\")\n","  ax[1].set_ylabel(\"Hidden Layer\")\n","\n","  # Plot output spikes\n","  splt.raster(spk2_rec.reshape(num_steps, -1), ax[2], c=\"black\", marker=\"|\")\n","  ax[2].set_ylabel(\"Output Spikes\")\n","  ax[2].set_ylim([0, 10])\n","\n","  plt.show()\n","\n","def dvs_animator(spike_data):\n","  fig, ax = plt.subplots()\n","  anim = splt.animator((spike_data[:,0] + spike_data[:,1]), fig, ax)\n","  return anim\n"],"metadata":{"id":"PhO1wRCqFPlr","cellView":"form"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["*What will I learn?*\n","\n","**The Basics:**\n","1. The leaky integrate-and-fire (`snn.Leaky`) neuron in 5 mins\n","2. Train an SNN classifier using surrogate gradient descent\n","\n","**The Fancier Stuff**\n","3. Population Codes\n","4. Recurrent SNNs and Spiking LSTMs\n","5. Learning precise spike-timing\n","6. Hardware Friendly Training\n","  - Weight Quantization with Brevitas\n","  - State Quantization\n","7. SNNs can sometimes be a pain in the ass to train. Hyperparameter Optimization with Optuna."],"metadata":{"id":"xLlnINAI9mgJ"}},{"cell_type":"markdown","source":["# 1. The Leaky Integrate-and-Fire Neuron\n","### (...in 5 mins)\n","\n"],"metadata":{"id":"-CS50cwuCW6n"}},{"cell_type":"code","source":["# imports\n","import snntorch as snn\n","from snntorch import spikeplot as splt\n","import torch\n","\n","# plotting\n","import matplotlib.pyplot as plt\n","from IPython.display import HTML"],"metadata":{"id":"H_TzogsCCcSe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["lif = snn.Leaky(beta=0.8) # LIF neuron with a decay rate of 0.8"],"metadata":{"id":"Ao9LfqkeEw-5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# setup inputs\n","num_steps = 200 # number of time-steps to simulate\n","\n","w = 0.8 # then run 0.15, 0.20, 0.21\n","# First run spike input\n","x = torch.cat((torch.zeros(10), torch.ones(1)*w, torch.zeros(189)))\n","\n","\n","# Small step current input\n","# w = 0.15, # then run 0.20, 0.21\n","# x = torch.cat((torch.zeros(10), torch.ones(190)*w), 0)\n","mem = torch.zeros(1)\n","spk = torch.zeros(1)"],"metadata":{"id":"bixHpBamE1AS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["mem_rec = []\n","spk_rec = []\n","\n","# neuron simulation\n","for step in range(num_steps):\n","  spk, mem = lif(x[step], mem)\n","  mem_rec.append(mem)\n","  spk_rec.append(spk)\n","\n","# convert lists to tensors\n","mem_rec = torch.stack(mem_rec)\n","spk_rec = torch.stack(spk_rec)\n","\n","plot_cur_mem_spk(x, mem_rec, spk_rec, thr_line=1, ylim_max1=1.0,\n","                 title=\"snn.Leaky Neuron Model\")"],"metadata":{"id":"5wTggA5XFJuI"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 2. Train an SNN Classifier \n","### (...in 10-ish mins)"],"metadata":{"id":"LEKAbrAACdDM"}},{"cell_type":"code","source":["# import\n","import torch.nn as nn\n","from torch.utils.data import DataLoader\n","from torchvision import datasets, transforms\n","import numpy as np\n","import itertools"],"metadata":{"id":"Z0DGl4FtChWO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Boilerplate: DataLoading the MNIST Dataset"],"metadata":{"id":"nftOdpyAGv7D"}},{"cell_type":"code","source":["# dataloader arguments\n","batch_size = 128\n","data_path='/data/mnist'\n","\n","dtype = torch.float\n","device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n","## if you're on M1 or M2 GPU:\n","# device = torch.device(\"mps\")"],"metadata":{"id":"SsM2Z5NXGu5z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Define a transform\n","transform = transforms.Compose([\n","            transforms.Resize((28, 28)),\n","            transforms.Grayscale(),\n","            transforms.ToTensor(),\n","            transforms.Normalize((0,), (1,))])\n","\n","mnist_train = datasets.MNIST(data_path, train=True, download=True, transform=transform)\n","mnist_test = datasets.MNIST(data_path, train=False, download=True, transform=transform)"],"metadata":{"id":"XqbYptgDHUPg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Create DataLoaders\n","train_loader = DataLoader(mnist_train, batch_size=batch_size, shuffle=True, drop_last=True)\n","test_loader = DataLoader(mnist_test, batch_size=batch_size, shuffle=True, drop_last=True)"],"metadata":{"id":"jSlS3gWZHXI0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Construct a Fully Connected SNN"],"metadata":{"id":"SJVhfNukHbsp"}},{"cell_type":"code","source":["# Network Architecture\n","num_inputs = 28*28\n","num_hidden = 1000\n","num_outputs = 10\n","\n","# Temporal Dynamics\n","num_steps = 25\n","beta = 0.95"],"metadata":{"id":"uu324fr_HhxV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Define Network\n","class Net(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","\n","        # Initialize layers\n","        self.fc1 = nn.Linear(num_inputs, num_hidden)\n","        self.lif1 = snn.Leaky(beta=beta)\n","        self.fc2 = nn.Linear(num_hidden, num_outputs)\n","        self.lif2 = snn.Leaky(beta=beta)\n","\n","    def forward(self, x):\n","\n","        # Initialize hidden states at t=0\n","        mem1 = self.lif1.init_leaky()\n","        mem2 = self.lif2.init_leaky()\n","        \n","        # Record the final layer\n","        spk2_rec = []\n","        mem2_rec = []\n","\n","        for step in range(num_steps):\n","            cur1 = self.fc1(x)\n","            spk1, mem1 = self.lif1(cur1, mem1)\n","            cur2 = self.fc2(spk1)\n","            spk2, mem2 = self.lif2(cur2, mem2)\n","            spk2_rec.append(spk2)\n","            mem2_rec.append(mem2)\n","\n","        return torch.stack(spk2_rec, dim=0), torch.stack(mem2_rec, dim=0)\n","        \n","# Load the network onto CUDA if available\n","net = Net().to(device)"],"metadata":{"id":"CkM1Z1EjHeW8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Training the SNN"],"metadata":{"id":"p8qBw03rHpn3"}},{"cell_type":"code","source":["loss = nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(net.parameters(), lr=5e-4, betas=(0.9, 0.999))\n","\n","num_epochs = 1\n","loss_hist = []\n","test_loss_hist = []\n","counter = 0\n","\n","# Outer training loop\n","for epoch in range(num_epochs):\n","    train_batch = iter(train_loader)\n","\n","    # Minibatch training loop\n","    for data, targets in train_batch:\n","        data = data.to(device)\n","        targets = targets.to(device)\n","\n","        # forward pass\n","        net.train()\n","        spk_rec, _ = net(data.flatten(1))\n","\n","        # initialize the loss & sum over time\n","        loss_val = torch.zeros((1), dtype=dtype, device=device)\n","        loss_val += loss(spk_rec.sum(0), targets)\n","\n","        # Gradient calculation + weight update\n","        optimizer.zero_grad()\n","        loss_val.backward()\n","        optimizer.step()\n","\n","        # Store loss history for future plotting\n","        loss_hist.append(loss_val.item())\n","\n","        # Print train/test loss/accuracy\n","        if counter % 10 == 0:\n","            print(f\"Iteration: {counter} \\t Train Loss: {loss_val.item()}\")\n","        counter += 1\n","\n","        if counter == 100:\n","          break"],"metadata":{"id":"1telBMU-HrIg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def measure_accuracy(model, dataloader):\n","  with torch.no_grad():\n","    model.eval()\n","    running_length = 0\n","    running_accuracy = 0\n","\n","    for data, targets in iter(dataloader):\n","      data = data.to(device)\n","      targets = targets.to(device)\n","\n","      # forward-pass\n","      spk_rec, _ = model(data.flatten(1))\n","      spike_count = spk_rec.sum(0)\n","      _, max_spike = spike_count.max(1)\n","\n","      # correct classes for one batch\n","      num_correct = (max_spike == targets).sum()\n","\n","      # total accuracy\n","      running_length += len(targets)\n","      running_accuracy += num_correct\n","    \n","    accuracy = (running_accuracy / running_length)\n","\n","    return accuracy.item()\n"],"metadata":{"id":"nHsdkuSlIS1E"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(f\"Test set accuracy: {measure_accuracy(net, test_loader)}\")"],"metadata":{"id":"oJHAltRCKGyx"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Convolutional SNN Classifier"],"metadata":{"id":"eFvZh1neMLtq"}},{"cell_type":"code","source":["# Define Network\n","class ConvNet(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","\n","        # Initialize layers\n","        self.conv1 = nn.Conv2d(1, 8, 5, padding=\"same\")\n","        self.lif1 = snn.Leaky(beta=beta)\n","        self.mp1 = nn.MaxPool2d(2)\n","        self.conv2 = nn.Conv2d(8, 24, 5, padding=\"same\")\n","        self.lif2 = snn.Leaky(beta=beta)\n","        self.mp2 = nn.MaxPool2d(2)\n","        self.fc = nn.Linear(7*7*24, 10)\n","        self.lif3 = snn.Leaky(beta=beta)\n","\n","    def forward(self, x):\n","\n","        # Initialize hidden states at t=0\n","        mem1 = self.lif1.init_leaky()\n","        mem2 = self.lif2.init_leaky()\n","        mem3 = self.lif3.init_leaky()\n","        \n","        # Record the final layer\n","        spk3_rec = []\n","        mem3_rec = []\n","\n","        for step in range(num_steps):\n","            cur1 = self.conv1(x)\n","            spk1, mem1 = self.lif1(self.mp1(cur1), mem1)\n","            cur2 = self.conv2(spk1)\n","            spk2, mem2 = self.lif2(self.mp2(cur2), mem2)\n","            cur3 = self.fc(spk2.flatten(1))\n","            spk3, mem3 = self.lif3(cur3, mem3)\n","\n","            spk3_rec.append(spk3)\n","            mem3_rec.append(mem3)\n","\n","        return torch.stack(spk3_rec, dim=0), torch.stack(mem3_rec, dim=0)\n","        \n","# Load the network onto CUDA if available\n","convnet = ConvNet().to(device)"],"metadata":{"id":"cjnd_xroMt0o"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["loss = nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(convnet.parameters(), lr=1e-2, betas=(0.9, 0.999))\n","\n","num_epochs = 1\n","loss_hist = []\n","test_loss_hist = []\n","counter = 0\n","\n","# Outer training loop\n","for epoch in range(num_epochs):\n","    train_batch = iter(train_loader)\n","\n","    # Minibatch training loop\n","    for data, targets in train_batch:\n","        data = data.to(device)\n","        targets = targets.to(device)\n","\n","        # forward pass\n","        convnet.train()\n","        spk_rec, _ = convnet(data)\n","\n","        # initialize the loss & sum over time\n","        loss_val = torch.zeros((1), dtype=dtype, device=device)\n","        loss_val = loss(spk_rec.sum(0), targets)\n","\n","        # Gradient calculation + weight update\n","        optimizer.zero_grad()\n","        loss_val.backward()\n","        optimizer.step()\n","\n","        # Store loss history for future plotting\n","        loss_hist.append(loss_val.item())\n","\n","        # Print train/test loss/accuracy\n","        if counter % 10 == 0:\n","            print(f\"Iteration: {counter} \\t Train Loss: {loss_val.item()}\")\n","        counter += 1\n","\n","        if counter == 100:\n","          break"],"metadata":{"id":"5fGM99IBOnuO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def measure_accuracy(model, dataloader):\n","  with torch.no_grad():\n","    model.eval()\n","    running_length = 0\n","    running_accuracy = 0\n","\n","    for data, targets in iter(dataloader):\n","      data = data.to(device)\n","      targets = targets.to(device)\n","\n","      # forward-pass\n","      spk_rec, _ = model(data)\n","      spike_count = spk_rec.sum(0)\n","      _, max_spike = spike_count.max(1)\n","\n","      # correct classes for one batch\n","      num_correct = (max_spike == targets).sum()\n","\n","      # total accuracy\n","      running_length += len(targets)\n","      running_accuracy += num_correct\n","    \n","    accuracy = (running_accuracy / running_length)\n","\n","    return accuracy.item()\n","\n","print(f\"ConvNet Accuracy: {measure_accuracy(convnet, test_loader)}\")"],"metadata":{"id":"j9i9VIMeQGNO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["<img src='https://i.ytimg.com/vi/Rt8LTxysC2s/maxresdefault.jpg' width=\"400\">\n","\n","# 3. Population Codes\n"],"metadata":{"id":"CwlMRIFpCiXq"}},{"cell_type":"code","source":["# Define Network\n","class Net(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","\n","        num_steps = 1\n","        num_outputs = 10\n","        population = 100\n","\n","        # Initialize layers\n","        self.fc1 = nn.Linear(num_inputs, num_hidden)\n","        self.lif1 = snn.Leaky(beta=beta)\n","        self.fc2 = nn.Linear(num_hidden, num_outputs*population)\n","        self.lif2 = snn.Leaky(beta=beta)\n","\n","    def forward(self, x):\n","\n","        # Initialize hidden states at t=0\n","        mem1 = self.lif1.init_leaky()\n","        mem2 = self.lif2.init_leaky()\n","        \n","        # Record the final layer\n","        spk2_rec = []\n","        mem2_rec = []\n","\n","        for step in range(num_steps):\n","            cur1 = self.fc1(x.flatten(1))\n","            spk1, mem1 = self.lif1(cur1, mem1)\n","            cur2 = self.fc2(spk1)\n","            spk2, mem2 = self.lif2(cur2, mem2)\n","            spk2_rec.append(spk2)\n","            mem2_rec.append(mem2)\n","\n","        return torch.stack(spk2_rec, dim=0), torch.stack(mem2_rec, dim=0)\n","        \n","# Load the network onto CUDA if available\n","popnet = Net().to(device)"],"metadata":{"id":"ZAXtcMpRDwk4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from snntorch import functional as SF"],"metadata":{"id":"5BO9chvmXhmv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["loss_fn = SF.ce_count_loss(population_code=True, num_classes=10)\n","optimizer = torch.optim.Adam(popnet.parameters(), lr=1e-3, betas=(0.9, 0.999))\n","\n","num_epochs = 1\n","loss_hist = []\n","test_loss_hist = []\n","counter = 0\n","\n","# Outer training loop\n","for epoch in range(num_epochs):\n","    train_batch = iter(train_loader)\n","\n","    # Minibatch training loop\n","    for data, targets in train_batch:\n","        data = data.to(device)\n","        targets = targets.to(device)\n","\n","        # forward pass\n","        popnet.train()\n","        spk_rec, _ = popnet(data)\n","\n","        # initialize the loss & sum over time\n","        loss_val = loss_fn(spk_rec, targets)\n","\n","        # Gradient calculation + weight update\n","        optimizer.zero_grad()\n","        loss_val.backward()\n","        optimizer.step()\n","\n","        # Store loss history for future plotting\n","        loss_hist.append(loss_val.item())\n","\n","        # Print train/test loss/accuracy\n","        if counter % 10 == 0:\n","            print(f\"Iteration: {counter} \\t Train Loss: {loss_val.item()}\")\n","        counter += 1\n","\n","        if counter == 100:\n","          break"],"metadata":{"id":"qeQ9o28dXNqT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def population_acc(testloader, model):\n","  with torch.no_grad():\n","    model.eval()\n","    running_accuracy = 0\n","    running_length = 0\n","    for data, labels in iter(testloader):\n","      data = data.to(device)\n","      labels = labels.to(device)\n","\n","      spk_rec, _ = model(data)\n","      running_accuracy += SF.accuracy_rate(spk_rec, labels, population_code=True, num_classes=10)\n","      running_length += len(labels)\n","    accuracy = running_accuracy*100 / running_length\n","    return accuracy "],"metadata":{"id":"9IF5HPHvX3YH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["accuracy = population_acc(test_loader, popnet)\n","print(f\"Population Code Accuracy: {accuracy}%\")"],"metadata":{"id":"0zwNSfORY-Rl"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 4. Recurrent SNNs and Spiking LSTMs\n","## 4.1 Neuromorphic DataLoading with Tonic\n","\n","[<img src='https://github.com/neuromorphs/tonic/blob/develop/docs/_static/tonic-logo-white.png?raw=true' width=\"150\">](https://github.com/neuromorphs/tonic/)"],"metadata":{"id":"_3-y-Z6pDw-W"}},{"cell_type":"code","source":["!pip install tonic --quiet"],"metadata":{"id":"PgGW1kliBgYK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import tonic\n","\n","dataset = tonic.datasets.POKERDVS(save_to='./data', train=True)\n","testset = tonic.datasets.POKERDVS(save_to='./data', train=False)\n","\n","events, target = dataset[0]\n","print(events)\n","tonic.utils.plot_event_grid(events)"],"metadata":{"id":"Vz3UPUG-Bfv3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tonic.datasets.POKERDVS.sensor_size"],"metadata":{"id":"xOtYPzuUBlhG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torchvision\n","from tonic import DiskCachedDataset\n","from torch.utils.data import DataLoader\n","\n","# time_window\n","frame_transform = tonic.transforms.Compose([tonic.transforms.Denoise(filter_time=10000), \n","                                    tonic.transforms.ToFrame(\n","                                        sensor_size=tonic.datasets.POKERDVS.sensor_size,\n","                                        time_window=1000)\n","                                     ])\n","\n","batch_size = 8\n","cached_trainset = DiskCachedDataset(dataset, transform=frame_transform, cache_path='./cache/pokerdvs/train')\n","cached_testset = DiskCachedDataset(testset, transform=frame_transform, cache_path='./cache/pokerdvs/test')\n","\n","trainloader = DataLoader(cached_trainset, batch_size=batch_size, collate_fn=tonic.collation.PadTensors(batch_first=False), shuffle=True)\n","testloader = DataLoader(cached_testset, batch_size=batch_size, collate_fn=tonic.collation.PadTensors(batch_first=False), shuffle=True)"],"metadata":{"id":"8JnjGcLSBokg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for data, labels in iter(trainloader):\n","  print(data.size())\n","  print(labels)\n","  break"],"metadata":{"id":"wfb6ec3lEr6n"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["animation = dvs_animator(data[:, 1])\n","HTML(animation.to_html5_video())"],"metadata":{"id":"8ZwZLPHfwV5a"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 4.2 Recurrent SNN"],"metadata":{"id":"hR3Xg09JF0Vf"}},{"cell_type":"code","source":["# Define Network\n","class RSNN(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","\n","        num_inputs = 35*35*2\n","        num_hidden = 512\n","        num_outputs = 4\n","        beta = 0.9\n","\n","        # Initialize layers\n","        self.fc1 = nn.Linear(num_inputs, num_hidden)\n","        self.lif1 = snn.RLeaky(beta=beta, linear_features=num_hidden)\n","        self.fc2 = nn.Linear(num_hidden, num_outputs)\n","        self.lif2 = snn.RLeaky(beta=beta, linear_features=num_outputs)\n","\n","    def forward(self, x):\n","\n","        # Initialize hidden states at t=0\n","        spk1, mem1 = self.lif1.init_rleaky()\n","        spk2, mem2 = self.lif2.init_rleaky()\n","        \n","        # Record the final layer\n","        spk2_rec = []\n","        mem2_rec = []\n","\n","        for step in range(x.size(0)):\n","            cur1 = self.fc1(x[step].flatten(1))\n","            spk1, mem1 = self.lif1(cur1, spk1, mem1)\n","            cur2 = self.fc2(spk1)\n","            spk2, mem2 = self.lif2(cur2, spk2, mem2)\n","            spk2_rec.append(spk2)\n","            mem2_rec.append(mem2)\n","\n","        return torch.stack(spk2_rec, dim=0), torch.stack(mem2_rec, dim=0)\n","\n","        \n","# Load the network onto CUDA if available\n","rnet = RSNN().to(device)"],"metadata":{"id":"YRvbELuvD1Gw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["loss = nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(rnet.parameters(), lr=1e-3, betas=(0.9, 0.999))\n","\n","num_epochs = 10\n","loss_hist = []\n","test_loss_hist = []\n","counter = 0\n","\n","# Outer training loop\n","for epoch in range(num_epochs):\n","\n","    # Minibatch training loop\n","    for data, targets in iter(trainloader):\n","        data = data.to(device)\n","        targets = targets.to(device)\n","\n","        # forward pass\n","        rnet.train()\n","        spk_rec, _ = rnet(data)\n","\n","        # initialize the loss & sum over time\n","        loss_val = torch.zeros((1), dtype=dtype, device=device)\n","        loss_val += loss(spk_rec.sum(0), targets)\n","\n","        # Gradient calculation + weight update\n","        optimizer.zero_grad()\n","        loss_val.backward()\n","        optimizer.step()\n","\n","        # Store loss history for future plotting\n","        loss_hist.append(loss_val.item())\n","\n","        # Print train/test loss/accuracy\n","        if counter % 10 == 0:\n","            print(f\"Iteration: {counter} \\t Train Loss: {loss_val.item()}\")\n","        counter += 1\n","\n","        if counter == 100:\n","          break"],"metadata":{"id":"2wrm2w7lbG3m"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(f\"RNet Accuracy: {measure_accuracy(rnet, testloader)}\")"],"metadata":{"id":"9hVQ6dezduj9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 4.3 Spiking Convolutional LSTM Unit (SCLU)"],"metadata":{"id":"3Ue7gXe7Rayn"}},{"cell_type":"code","source":["# Define Network\n","class SCLU(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","\n","        num_outputs = 4\n","        beta = 0.9\n","\n","        # Initialize layers\n","        self.sclu1 = snn.SConv2dLSTM(2, 8, 5, max_pool=2, threshold=0.1)\n","        self.sclu2 = snn.SConv2dLSTM(8, 16, 5, max_pool=2, threshold=0.1)\n","        self.fc = nn.Linear(8*8*16, 4)\n","        self.lif = snn.Leaky(beta=beta)\n","\n","    def forward(self, x):\n","\n","        # Initialize hidden states at t=0\n","        syn1, mem1 = self.sclu1.init_sconv2dlstm()\n","        syn2, mem2 = self.sclu2.init_sconv2dlstm()\n","        mem3 = self.lif.init_leaky()\n","        \n","        # Record the final layer\n","        spk3_rec = []\n","        mem3_rec = []\n","\n","        for step in range(x.size(0)):\n","            spk1, syn1, mem1 = self.sclu1(x[step], syn1, mem1)\n","            spk2, syn2, mem2 = self.sclu2(spk1, syn2, mem2)\n","            cur2 = self.fc(spk2.flatten(1))\n","            spk3, mem3 = self.lif(cur2, mem3)\n","\n","            spk3_rec.append(spk3)\n","            mem3_rec.append(mem3)\n","\n","        return torch.stack(spk3_rec, dim=0), torch.stack(mem3_rec, dim=0)\n","\n","        \n","# Load the network onto CUDA if available\n","sclu = SCLU().to(device)"],"metadata":{"id":"uqZZNjcPRadp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["loss = nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(sclu.parameters(), lr=1e-3, betas=(0.9, 0.999))\n","\n","num_epochs = 10\n","loss_hist = []\n","test_loss_hist = []\n","counter = 0\n","\n","# Outer training loop\n","for epoch in range(num_epochs):\n","\n","    # Minibatch training loop\n","    for data, targets in iter(trainloader):\n","        data = data.to(device)\n","        targets = targets.to(device)\n","\n","        # forward pass\n","        sclu.train()\n","        spk_rec, _ = sclu(data)\n","\n","        # initialize the loss & sum over time\n","        loss_val = torch.zeros((1), dtype=dtype, device=device)\n","        loss_val += loss(spk_rec.sum(0), targets)\n","\n","        # Gradient calculation + weight update\n","        optimizer.zero_grad()\n","        loss_val.backward()\n","        optimizer.step()\n","\n","        # Store loss history for future plotting\n","        loss_hist.append(loss_val.item())\n","\n","        # Print train/test loss/accuracy\n","        if counter % 10 == 0:\n","            print(f\"Iteration: {counter} \\t Train Loss: {loss_val.item()}\")\n","        counter += 1\n","\n","        if counter == 100:\n","          break"],"metadata":{"id":"FSyvR8ZIRWfj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(f\"SCLU Accuracy: {measure_accuracy(sclu, testloader)}\")"],"metadata":{"id":"Nx11Ubl6U13N"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["spk_rec.size()"],"metadata":{"id":"8IHkC8-9aOWD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(targets[0])\n","spk_rec[:, 0]"],"metadata":{"id":"56wHzZEqage_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 5. Precise Spike-Timing"],"metadata":{"id":"3EVG5EGdD3zD"}},{"cell_type":"code","source":["net = Net().to(device)"],"metadata":{"id":"6hPzs0J9Y8x6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["loss = SF.mse_temporal_loss(on_target=5, off_target=20)\n","optimizer = torch.optim.Adam(net.parameters(), lr=1e-3, betas=(0.9, 0.999))\n","\n","num_epochs = 100\n","loss_hist = []\n","test_loss_hist = []\n","counter = 0\n","\n","# Outer training loop\n","for epoch in range(num_epochs):\n","\n","    # Minibatch training loop\n","    for data, targets in iter(train_loader):\n","        data = data.to(device)\n","        targets = targets.to(device)\n","\n","        # forward pass\n","        sclu.train()\n","        spk_rec, _ = sclu(data)\n","\n","        # initialize the loss & sum over time\n","        # loss_val = torch.zeros((1), dtype=dtype, device=device)\n","        loss_val = loss(spk_rec, targets)\n","\n","        # Gradient calculation + weight update\n","        optimizer.zero_grad()\n","        loss_val.backward()\n","        optimizer.step()\n","\n","        # Store loss history for future plotting\n","        loss_hist.append(loss_val.item())\n","\n","        # Print train/test loss/accuracy\n","        if counter % 10 == 0:\n","            print(f\"Iteration: {counter} \\t Train Loss: {loss_val.item()}\")\n","        counter += 1\n","\n","        # if counter == 100:\n","        #   break"],"metadata":{"id":"MP-BLuS6D5vR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def temporal_accuracy(model, dataloader):\n","  with torch.no_grad():\n","    model.eval()\n","    running_length = 0\n","    running_accuracy = 0\n","\n","    for data, targets in iter(dataloader):\n","      data = data.to(device)\n","      targets = targets.to(device)\n","\n","      # forward-pass\n","      spk_rec, _ = model(data)\n","\n","      # total accuracy\n","      running_length += len(targets)\n","      running_accuracy += SF.accuracy_temporal(spk_rec, targets)\n","\n","    \n","    accuracy = (running_accuracy / running_length)\n","\n","    return accuracy.item()\n"],"metadata":{"id":"f8Z9k4mYYDFG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(f\"SCLU Accuracy: {temporal_accuracy(sclu, testloader)}\")"],"metadata":{"id":"D-FwmkUeXqKP"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 6. Hardware Friendly Training\n","## 6.1 Weight Quantization"],"metadata":{"id":"Z9vrb2zUD6S-"}},{"cell_type":"code","source":["!pip install brevitas --quiet"],"metadata":{"id":"icK4WzuL-2QA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import brevitas.nn as qnn\n","\n","# Define Network\n","class Net(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","\n","        # Initialize layers\n","        self.fc1 = qnn.QuantLinear(num_inputs, num_hidden, weight_bit_width=8, bias=False)\n","        self.lif1 = snn.Leaky(beta=beta)\n","        self.fc2 = qnn.QuantLinear(num_hidden, num_outputs, weight_bit_width=8, bias=False)\n","        self.lif2 = snn.Leaky(beta=beta)\n","\n","    def forward(self, x):\n","\n","        # Initialize hidden states at t=0\n","        mem1 = self.lif1.init_leaky()\n","        mem2 = self.lif2.init_leaky()\n","        \n","        # Record the final layer\n","        spk2_rec = []\n","        mem2_rec = []\n","\n","        for step in range(num_steps):\n","            cur1 = self.fc1(x)\n","            spk1, mem1 = self.lif1(cur1, mem1)\n","            cur2 = self.fc2(spk1)\n","            spk2, mem2 = self.lif2(cur2, mem2)\n","            spk2_rec.append(spk2)\n","            mem2_rec.append(mem2)\n","\n","        return torch.stack(spk2_rec, dim=0), torch.stack(mem2_rec, dim=0)\n","        \n","# Load the network onto CUDA if available\n","net = Net().to(device)"],"metadata":{"id":"PiZYTMA6D-YL"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 6.2 State Quantization"],"metadata":{"id":"JvRzLHdjD-6S"}},{"cell_type":"code","source":["from snntorch.functional import quant\n","\n","# Define Network\n","class Net(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","\n","        qlif = quant.state_quant(num_bits=8, uniform=False, thr_centered=False)\n","\n","\n","        # Initialize layers\n","        self.fc1 = qnn.QuantLinear(num_inputs, num_hidden, weight_bit_width=8, bias=False)\n","        self.lif1 = snn.Leaky(beta=beta, state_quant=qlif)\n","        self.fc2 = qnn.QuantLinear(num_hidden, num_outputs, weight_bit_width=8, bias=False)\n","        self.lif2 = snn.Leaky(beta=beta, state_quant=qlif)\n","\n","    def forward(self, x):\n","\n","        # Initialize hidden states at t=0\n","        mem1 = self.lif1.init_leaky()\n","        mem2 = self.lif2.init_leaky()\n","        \n","        # Record the final layer\n","        spk2_rec = []\n","        mem2_rec = []\n","\n","        for step in range(num_steps):\n","            cur1 = self.fc1(x)\n","            spk1, mem1 = self.lif1(cur1, mem1)\n","            cur2 = self.fc2(spk1)\n","            spk2, mem2 = self.lif2(cur2, mem2)\n","            spk2_rec.append(spk2)\n","            mem2_rec.append(mem2)\n","\n","        return torch.stack(spk2_rec, dim=0), torch.stack(mem2_rec, dim=0)\n","        \n","# Load the network onto CUDA if available\n","net = Net().to(device)"],"metadata":{"id":"tAaafUczEAu_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 7. Hyperparameter Optimization with Optuna"],"metadata":{"id":"rNV1aGoRECig"}},{"cell_type":"code","source":["!pip install optuna --quiet\n","!pip install optuna-dashboard"],"metadata":{"id":"j7BmK8d7EHTS","executionInfo":{"status":"ok","timestamp":1677774600533,"user_tz":480,"elapsed":18062,"user":{"displayName":"Jason Eshraghian","userId":"17871655902437888594"}},"outputId":"17e8201a-99be-4354-f5bb-636e410a7924","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m365.3/365.3 KB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m210.5/210.5 KB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.7/78.7 KB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting optuna-dashboard\n","  Downloading optuna_dashboard-0.8.1-py3-none-any.whl (2.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m42.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from optuna-dashboard) (23.0)\n","Requirement already satisfied: optuna>=2.4.0 in /usr/local/lib/python3.8/dist-packages (from optuna-dashboard) (3.1.0)\n","Collecting bottle\n","  Downloading bottle-0.12.24-py3-none-any.whl (90 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.2/90.2 KB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: scikit-learn in /usr/local/lib/python3.8/dist-packages (from optuna-dashboard) (1.0.2)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from optuna>=2.4.0->optuna-dashboard) (4.64.1)\n","Requirement already satisfied: colorlog in /usr/local/lib/python3.8/dist-packages (from optuna>=2.4.0->optuna-dashboard) (6.7.0)\n","Requirement already satisfied: cmaes>=0.9.1 in /usr/local/lib/python3.8/dist-packages (from optuna>=2.4.0->optuna-dashboard) (0.9.1)\n","Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.8/dist-packages (from optuna>=2.4.0->optuna-dashboard) (1.4.46)\n","Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.8/dist-packages (from optuna>=2.4.0->optuna-dashboard) (1.9.4)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.8/dist-packages (from optuna>=2.4.0->optuna-dashboard) (6.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from optuna>=2.4.0->optuna-dashboard) (1.22.4)\n","Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->optuna-dashboard) (1.7.3)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->optuna-dashboard) (1.2.0)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->optuna-dashboard) (3.1.0)\n","Requirement already satisfied: importlib-resources in /usr/local/lib/python3.8/dist-packages (from alembic>=1.5.0->optuna>=2.4.0->optuna-dashboard) (5.12.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.8/dist-packages (from alembic>=1.5.0->optuna>=2.4.0->optuna-dashboard) (6.0.0)\n","Requirement already satisfied: Mako in /usr/local/lib/python3.8/dist-packages (from alembic>=1.5.0->optuna>=2.4.0->optuna-dashboard) (1.2.4)\n","Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.8/dist-packages (from sqlalchemy>=1.3.0->optuna>=2.4.0->optuna-dashboard) (2.0.2)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata->alembic>=1.5.0->optuna>=2.4.0->optuna-dashboard) (3.15.0)\n","Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.8/dist-packages (from Mako->alembic>=1.5.0->optuna>=2.4.0->optuna-dashboard) (2.1.2)\n","Installing collected packages: bottle, optuna-dashboard\n","Successfully installed bottle-0.12.24 optuna-dashboard-0.8.1\n"]}]},{"cell_type":"code","source":["# imports\n","import optuna\n","import joblib"],"metadata":{"id":"Tg_y39e87-TH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def sample_parameters(trial):\n","    \"\"\"Initialize randomly sampled parameters.\"\"\"\n","\n","    batch_size = trial.suggest_categorical('batch_size', [32, 64, 128, 256])\n","    lr = trial.suggest_float('lr', 5e-5, 1e-2, log=True)\n","    dropout_1 = trial.suggest_float('dropout_1', 0, 1)\n","    dropout_2 = trial.suggest_float('dropout_2', 0, 1)\n","    beta_1 = trial.suggest_float('beta_1', 0, 1)\n","    beta_2 = trial.suggest_float('beta_2', 0, 1)\n","    threshold_1 = trial.suggest_float('threshold_1', 1e-3, 1, log=True)\n","    threshold_2 = trial.suggest_float('threshold_2', 1e-3, 1, log=True)\n","\n","    return (batch_size, lr, dropout_1, dropout_2, beta_1, beta_2, threshold_1, threshold_2)"],"metadata":{"id":"el71FWNiKlFC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# parameters to optimize\n","\n","def config(trial):\n","    params = sample_parameters(trial)\n","    batch_size, lr, dropout_1, dropout_2, beta_1, beta_2, threshold_1, threshold_2 = params\n","\n","\n","    config = {\n","        'batch_size' : batch_size,\n","        'lr' : lr,\n","        'dropout_1' : dropout_1,\n","        'dropout_2' : dropout_2,\n","        'beta_1' : beta_1,\n","        'beta_2' : beta_2,\n","        'threshold_1' : threshold_1,\n","        'threshold_2' : threshold_2\n","    }\n","\n","    measure_accuracy(convnet, test_loader)}\"\n"],"metadata":{"id":"ODBSkTteKrbg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def objective(trial):\n","\n","    # Training loop - optimize for test-acc\n","\n","    return test_acc"],"metadata":{"id":"soZj4vLnKfF-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["n_trials = 5\n","study_name = \"optuna_test\"\n","\n","\n","pruner = optuna.pruners.SuccessiveHalvingPruner()\n","sampler = optuna.samplers.TPESampler()\n","storage_name = \"sqlite:///{}.db\".format(study_name)\n","study = optuna.create_study(study_name=study_name, sampler=sampler, direction='maximize', pruner=pruner, storage=storage_name, load_if_exists=True)\n","study.optimize(objective, n_trials=n_trials)\n","\n","# Create a dataframe from the study.\n","df = study.trials_dataframe()\n","\n","print(f\"Best config: {study.best_params}\")\n","joblib.dump(study, 'optuna.pkl')"],"metadata":{"id":"CPGprbkp9Y-y"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Interested in Becoming a Contributor?\n","\n","Random Ideas:\n","\n","* Neurons with adaptive thresholds\n","\n","* Different types of neurons, e.g., Legendre Memory Units\n","\n","* Write up tutorials! From integrating new learning rules, combining snnTorch with liquid state machines, or a spiking version of the forward-forward algorithm?\n","\n","* Dendritic Computation. Integration with Dendrify?"],"metadata":{"id":"DXEMfIdj-SKd"}},{"cell_type":"markdown","source":["## Current Opportunities for Neuromorphs:\n","\n","* Telluride 2023 Applications are open! Call for applications [here](https://sites.google.com/view/telluride-2023/home?authuser=0).\n","* Submit your work to [APL Machine Learning](https://aip.scitation.org/journal/aml)\n","* Submit your work to the Special Issue on Linking Neuro-AI with Neuromorphic Computing to the [IEEE Journal on Emerging Topics in Circuits and Systems](https://ieee-cas.org/files/ieeecass/2023-02/JETCAS_CFP_23-Q4-r2.pdf)\n","\n","* ISCAS 2023 Tutorial: [How to Build Open-Source Neuromorphic Hardware and Algorithms](https://iscas2023.org/tutorials) by Jason Eshraghian & Charlotte Frenkel\n"],"metadata":{"id":"pNrFs3ro-xUm"}}]}